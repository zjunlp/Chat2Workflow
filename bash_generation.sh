python chatllm.py \
    --input_file dataset/query.json \
    --model_name deepseek-chat \
    --temperature 0.7 \
    --max_tokens 8192